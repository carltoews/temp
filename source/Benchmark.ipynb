{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "*This notebook implements a variety of algorithms, and checks to see how they work on a set of test images.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flickr API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import flickr functionality and record credentials*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import io\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "#pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish connections to Flickr and Google\n",
    "\n",
    "Establish Flickr connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = u'37528c980c419716e0879a417ef8211c'\n",
    "api_secret = u'41075654a535c203'\n",
    "\n",
    "# establish connection\n",
    "flickr = flickrapi.FlickrAPI(api_key, api_secret, format='parsed-json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish Google connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Bucket: toews-images>]\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \\\n",
    "#\"/Users/ctoews/Documents/Insight/Project/googleAPI/MyFirstProject-76680dcd1ad6.json\"\n",
    "\n",
    "def explicit():\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(\n",
    "        '/Users/ctoews/Documents/Insight/Project/googleAPI/MyFirstProject-76680dcd1ad6.json')\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)\n",
    "\n",
    "# authenticate google\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \\\n",
    "\"/Users/ctoews/Documents/Insight/Project/googleAPI/MyFirstProject-76680dcd1ad6.json\"\n",
    "    \n",
    "explicit()\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = types.Image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_urls(photoset):\n",
    "    urls = []\n",
    "    for photo in photoset['photoset']['photo']:\n",
    "        url = \"https://farm\" + str(photo['farm']) + \".staticflickr.com/\" + photo['server'] + \"/\" + \\\n",
    "              photo['id'] + \"_\" + photo['secret'] + \".jpg\"\n",
    "        urls.append(url)    \n",
    "    return urls\n",
    "    \n",
    "# get bad photo ids\n",
    "badset   = flickr.photosets.getPhotos(user_id='138072685@N02',photoset_id='72157690932631201')\n",
    "goodset   = flickr.photosets.getPhotos(user_id='138072685@N02',photoset_id='72157690932695551')\n",
    "bad_urls = assemble_urls(badset)\n",
    "good_urls = assemble_urls(goodset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://farm5.staticflickr.com/4613/25993550898_065d0b3880.jpg',\n",
       " 'https://farm5.staticflickr.com/4764/28087291009_3d20f9a4a2.jpg',\n",
       " 'https://farm5.staticflickr.com/4619/28087290939_6d2f4261b4.jpg',\n",
       " 'https://farm5.staticflickr.com/4717/25993550618_14c87ffa16.jpg',\n",
       " 'https://farm5.staticflickr.com/4714/28087290769_b7df9499e8.jpg',\n",
       " 'https://farm5.staticflickr.com/4626/28087290719_61ed3cca32.jpg',\n",
       " 'https://farm5.staticflickr.com/4625/28087290709_4dffc807d3.jpg',\n",
       " 'https://farm5.staticflickr.com/4719/28087290669_a2beb02023.jpg',\n",
       " 'https://farm5.staticflickr.com/4751/28087291099_93066c995e.jpg',\n",
       " 'https://farm5.staticflickr.com/4629/28087290529_9c762237c2.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Authenticate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Bucket: toews-images>]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Explicitly use service account credentials by specifying the private key\n",
    "# file.\n",
    "storage_client = storage.Client.from_service_account_json(\n",
    "    '/Users/ctoews/Documents/Insight/Project/googleAPI/MyFirstProject-76680dcd1ad6.json')\n",
    "\n",
    "# Make an authenticated API request\n",
    "buckets = list(storage_client.list_buckets())\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pass photo URLs to Google Vision for labelling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = []\n",
    "for url in bad_urls:\n",
    "    image.source.image_uri = url\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    these_labels = ''\n",
    "    for label in labels:\n",
    "        these_labels += (label.description + ' ')\n",
    "    bad_labels.append(these_labels)\n",
    "    \n",
    "good_labels = []\n",
    "for url in good_urls:\n",
    "    image.source.image_uri = url\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    these_labels = ''\n",
    "    for label in labels:\n",
    "        these_labels += (label.description + ' ')\n",
    "    good_labels.append(these_labels)\n",
    "    \n",
    "bl = pd.DataFrame(bad_labels,columns=['labels'])\n",
    "gl = pd.DataFrame(good_labels,columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.source.image_uri = url\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://farm5.staticflickr.com/4623/39834715572_1559b597ec.jpg',\n",
       " 'https://farm5.staticflickr.com/4605/39834715692_e499c7d71f.jpg',\n",
       " 'https://farm5.staticflickr.com/4630/39834715602_3314a7eaf4.jpg',\n",
       " 'https://farm5.staticflickr.com/4653/39834716592_efe5420940.jpg',\n",
       " 'https://farm5.staticflickr.com/4674/39834715812_c9b8157bc5.jpg',\n",
       " 'https://farm5.staticflickr.com/4708/39834715942_d993de82f6.jpg',\n",
       " 'https://farm5.staticflickr.com/4673/39834716042_ae01ea0ceb.jpg',\n",
       " 'https://farm5.staticflickr.com/4699/39834716362_1c539bed39.jpg',\n",
       " 'https://farm5.staticflickr.com/4611/39834716422_36a95d3667.jpg',\n",
       " 'https://farm5.staticflickr.com/4723/39834716482_00c2ce1e07.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sentiment=[]\n",
    "for i in np.arange(10):\n",
    "    doc = TextBlob(good_labels[i])\n",
    "    #print(doc.sentiment[0])\n",
    "    good_sentiment.append(doc.sentiment)\n",
    "    \n",
    "bad_sentiment=[]\n",
    "for i in np.arange(10):\n",
    "    doc = TextBlob(bad_labels[i])\n",
    "    #print(doc.sentiment[0])\n",
    "    bad_sentiment.append(doc.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bad_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels=pd.concat([bl,gl])\n",
    "for i in all_labels['labels']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match to poems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "import poeml_utility as pml\n",
    "\n",
    "parser = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = spacy.load('en')\n",
    "allvecs = pd.read_pickle('allvecs.pkl')\n",
    "with open('sharespeares_stopwords.pkl','rb') as file:\n",
    "    shakespeares_stopwords = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "import string\n",
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + list(shakespeares_stopwords))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + \\\n",
    "          [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip blanks and other terrible things\n",
    "data = all_labels['labels']\n",
    "data_clean=[]\n",
    "for label in data:\n",
    "    data_clean.append(pml.cleanText(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() \n",
    "                      if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "# tokenize\n",
    "label_token = []\n",
    "for label in data_clean:\n",
    "    label_token.append(tokenizeText(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine\n",
    "input_label = []\n",
    "for label in label_token:\n",
    "    input_label.append(' '.join(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy # pandas-mysql interface library\n",
    "import sqlalchemy.exc # exception handling\n",
    "import poeml_utility as pml\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "engine = pml.connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse\n",
    "parsed_labels = []\n",
    "for label in all_labels['labels']:\n",
    "    parsed_labels.append(parser(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the embeddings for the picture labels\n",
    "\n",
    "good_pics_vecs = np.zeros((10,384))\n",
    "for i in np.arange(10):\n",
    "    good_pics_vecs[i,:] = parser(str(parsed_labels[i])).vector\n",
    "    \n",
    "bad_pics_vecs = np.zeros((10,384))\n",
    "for i in np.arange(10):\n",
    "    bad_pics_vecs[i,:] = parser(str(parsed_labels[10+i])).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from sonnet_sentences order by index;\"\n",
    "sonnet_sentences = pd.read_sql(query,engine)\n",
    "len(sonnet_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from poem_embeddings order by index;\"\n",
    "poem_embeddings = pd.read_sql(query,engine)\n",
    "poem_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify test cases\n",
    "bad_idx = 282\n",
    "good_idx= 35\n",
    "\n",
    "# extract relevant embeddings\n",
    "bad_vec = poem_embeddings.iloc[bad_idx,1:]\n",
    "good_vec = poem_embeddings.iloc[good_idx,1:]\n",
    "\n",
    "# check\n",
    "print(\"bad: \\n\",sonnet_sentences.iloc[bad_idx,2])\n",
    "print(\"good: \\n\",sonnet_sentences.iloc[good_idx,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = cosine_distances(bad_vec.values.reshape((1,-1)), bad_pics_vecs).flatten()\n",
    "bg = cosine_distances(bad_vec.values.reshape((1,-1)), good_pics_vecs).flatten()\n",
    "gb = cosine_distances(good_vec.values.reshape((1,-1)), bad_pics_vecs).flatten()\n",
    "gg = cosine_distances(good_vec.values.reshape((1,-1)), good_pics_vecs).flatten()\n",
    "test_results = pd.DataFrame(data={'bb':bb,'bg':bg,'gb':gb,'gg':gg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bad poem: \\n\",np.sign(test_results['bb']-test_results['bg']))\n",
    "print(\"good poem: \\n\",np.sign(test_results['gg']-test_results['gb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = euclidean_distances(bad_vec.values.reshape((1,-1)), bad_pics_vecs).flatten()\n",
    "bg = euclidean_distances(bad_vec.values.reshape((1,-1)), good_pics_vecs).flatten()\n",
    "gb = euclidean_distances(good_vec.values.reshape((1,-1)), bad_pics_vecs).flatten()\n",
    "gg = euclidean_distances(good_vec.values.reshape((1,-1)), good_pics_vecs).flatten()\n",
    "test_results = pd.DataFrame(data={'bb':bb,'bg':bg,'gb':gb,'gg':gg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bad poem: \\n\",np.sign(test_results['bb']-test_results['bg']))\n",
    "print(\"good poem: \\n\",np.sign(test_results['gg']-test_results['gb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pics_vecs = normalize(bad_pics_vecs,axis=1)\n",
    "good_pics_vecs = normalize(good_pics_vecs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del poem_embeddings['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=cosine_distances(good_vec.reshape((1,-1)),poem_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.argsort(dists)\n",
    "dists[0,idx[0][0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists[0,idx[0][0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=parser(\"god\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with new testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_url = \"https://www.flickr.com/photos/138072685@N02/albums\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flickr   = flickr.photosets.getPhotos(user_id='138072685@N02',photoset_id='72157669045554809')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = assemble_urls(test_flickr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for url in test_urls:\n",
    "    image.source.image_uri = url\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    these_labels = ''\n",
    "    for label in labels:\n",
    "        these_labels += (label.description + ' ')\n",
    "    test_labels.append(these_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from quotes;\"\n",
    "quotes = pd.read_sql(query,engine)\n",
    "quotes.quoteText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotevecs = pd.read_pickle('quote_vecs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.loc[quotes.quoteText.str.contains('sun'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = quotes.iloc[1362,:]\n",
    "q2 = quotes.iloc[987,:]\n",
    "q1v = parser(q1.quoteText).vector\n",
    "q2v = parser(q2.quoteText).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "parser = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_text = test_labels[-1]\n",
    "image_text\n",
    "image_vector = parser(image_text)\n",
    "image_vector=image_vector.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(image_vector.reshape(1,-1),q2v.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(q1v.reshape(1,-1),q2v.reshape(1,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1v.reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
